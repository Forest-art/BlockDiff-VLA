{
  "results": {
    "chartqa_lite": {
      "alias": "chartqa_lite",
      "relaxed_overall,none": 0.0,
      "relaxed_overall_stderr,none": 0.0,
      "relaxed_overall_stderr_clt,none": 0.0,
      "relaxed_overall_stderr_clustered,none": "N/A",
      "relaxed_human_split,none": 0.0,
      "relaxed_human_split_stderr,none": 0.0,
      "relaxed_human_split_stderr_clt,none": 0.0,
      "relaxed_human_split_stderr_clustered,none": "N/A",
      "relaxed_augmented_split,none": 0.0,
      "relaxed_augmented_split_stderr,none": 0.0,
      "relaxed_augmented_split_stderr_clt,none": 0.0,
      "relaxed_augmented_split_stderr_clustered,none": "N/A"
    },
    "docvqa_val_lite": {
      "alias": "docvqa_val_lite",
      "anls,none": 0.0,
      "anls_stderr,none": 0.0,
      "anls_stderr_clt,none": 0.0,
      "anls_stderr_clustered,none": "N/A"
    },
    "textvqa_val_lite": {
      "alias": "textvqa_val_lite",
      "exact_match,none": 0.02,
      "exact_match_stderr,none": 0.014070529413628963,
      "exact_match_stderr_clt,none": 0.014070529413628966,
      "exact_match_stderr_clustered,none": "N/A",
      "submission,none": null,
      "submission_stderr,none": "N/A",
      "submission_stderr_clt,none": "N/A",
      "submission_stderr_clustered,none": "N/A"
    },
    "vizwiz_vqa_val_lite": {
      "alias": "vizwiz_vqa_val_lite",
      "exact_match,none": 0.0,
      "exact_match_stderr,none": 0.0,
      "exact_match_stderr_clt,none": 0.0,
      "exact_match_stderr_clustered,none": "N/A",
      "submission,none": [],
      "submission_stderr,none": []
    }
  },
  "group_subtasks": {
    "chartqa_lite": [],
    "docvqa_val_lite": [],
    "textvqa_val_lite": [],
    "vizwiz_vqa_val_lite": []
  },
  "configs": {
    "chartqa_lite": {
      "task": "chartqa_lite",
      "dataset_path": "lmms-lab/LMMs-Eval-Lite",
      "dataset_name": "chartqa",
      "dataset_kwargs": {
        "token": false
      },
      "test_split": "lite",
      "full_docs": false,
      "process_results_use_image": false,
      "doc_to_visual": "<function chartqa_doc_to_visual at 0x1554293c7520>",
      "doc_to_text": "<function chartqa_doc_to_text at 0x1554292b8280>",
      "doc_to_target": "answer",
      "process_results": "<function chartqa_process_results at 0x1554292b8670>",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "relaxed_overall",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "relaxed_human_split",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "relaxed_augmented_split",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "generate_until",
      "generation_kwargs": {
        "max_new_tokens": 16,
        "temperature": 0.0,
        "do_sample": false,
        "until": [
          "\n\n"
        ]
      },
      "repeats": 1,
      "should_decontaminate": false,
      "score_key": "score",
      "metadata": [
        {
          "version": 0.0
        }
      ],
      "lmms_eval_specific_kwargs": {
        "default": {
          "pre_prompt": "",
          "post_prompt": "\nAnswer the question with a single word."
        },
        "qwen_vl": {
          "pre_prompt": "",
          "post_prompt": " Answer:"
        },
        "pre_prompt": "",
        "post_prompt": "\nAnswer the question with a single word."
      }
    },
    "docvqa_val_lite": {
      "task": "docvqa_val_lite",
      "dataset_path": "lmms-lab/LMMs-Eval-Lite",
      "dataset_name": "docvqa_val",
      "dataset_kwargs": {
        "token": false
      },
      "test_split": "lite",
      "full_docs": false,
      "process_results_use_image": false,
      "doc_to_visual": "<function docvqa_doc_to_visual at 0x15521a357eb0>",
      "doc_to_text": "<function docvqa_doc_to_text at 0x15521a374550>",
      "doc_to_target": "answers",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "anls",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "generate_until",
      "generation_kwargs": {
        "max_new_tokens": 32,
        "temperature": 0.0,
        "do_sample": false,
        "until": [
          "\n\n"
        ]
      },
      "repeats": 1,
      "should_decontaminate": false,
      "score_key": "score",
      "lmms_eval_specific_kwargs": {
        "default": {
          "pre_prompt": "",
          "post_prompt": "\nAnswer the question using a single word or phrase."
        },
        "qwen_vl": {
          "pre_prompt": "",
          "post_prompt": " Answer:"
        },
        "pre_prompt": "",
        "post_prompt": "\nAnswer the question using a single word or phrase."
      }
    },
    "textvqa_val_lite": {
      "task": "textvqa_val_lite",
      "dataset_path": "lmms-lab/LMMs-Eval-Lite",
      "dataset_name": "textvqa_val",
      "test_split": "lite",
      "full_docs": false,
      "process_results_use_image": false,
      "doc_to_visual": "<function textvqa_doc_to_visual at 0x15521a374f70>",
      "doc_to_text": "<function textvqa_doc_to_text at 0x15521a3767a0>",
      "doc_to_target": "answer",
      "process_results": "<function textvqa_process_results at 0x15521a376b90>",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "exact_match",
          "aggregation": "mean",
          "higher_is_better": true,
          "ignore_case": true,
          "ignore_punctuation": true
        },
        {
          "metric": "submission",
          "aggregation": "<function textvqa_aggregate_submissions at 0x15521a377130>",
          "higher_is_better": true
        }
      ],
      "output_type": "generate_until",
      "generation_kwargs": {
        "until": [
          "ASSISTANT:"
        ]
      },
      "repeats": 1,
      "should_decontaminate": false,
      "score_key": "score",
      "lmms_eval_specific_kwargs": {
        "default": {
          "pre_prompt": "",
          "post_prompt": "\nAnswer the question using a single word or phrase.",
          "ocr": false
        },
        "qwen_vl": {
          "pre_prompt": "",
          "post_prompt": " Answer:"
        },
        "pre_prompt": "",
        "post_prompt": "\nAnswer the question using a single word or phrase.",
        "ocr": false
      }
    },
    "vizwiz_vqa_val_lite": {
      "task": "vizwiz_vqa_val_lite",
      "dataset_path": "lmms-lab/LMMs-Eval-Lite",
      "dataset_name": "vizwiz_vqa_val",
      "test_split": "lite",
      "full_docs": false,
      "process_results_use_image": false,
      "doc_to_visual": "<function vizwiz_vqa_doc_to_visual at 0x15521a3fc0d0>",
      "doc_to_text": "<function vizwiz_vqa_doc_to_text at 0x15521a377d00>",
      "doc_to_target": "answer",
      "process_results": "<function vizwiz_vqa_process_results at 0x15521a3752d0>",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "exact_match",
          "aggregation": "mean",
          "higher_is_better": true,
          "ignore_case": true,
          "ignore_punctuation": true
        }
      ],
      "output_type": "generate_until",
      "generation_kwargs": {
        "until": [
          "ASSISTANT:"
        ]
      },
      "repeats": 1,
      "should_decontaminate": false,
      "score_key": "score",
      "metadata": [
        {
          "version": 0.0
        }
      ],
      "lmms_eval_specific_kwargs": {
        "default": {
          "pre_prompt": "",
          "post_prompt": "\nWhen the provided information is insufficient, respond with 'Unanswerable'.\nAnswer the question using a single word or phrase."
        },
        "pre_prompt": "",
        "post_prompt": "\nWhen the provided information is insufficient, respond with 'Unanswerable'.\nAnswer the question using a single word or phrase."
      }
    }
  },
  "versions": {
    "chartqa_lite": "Yaml",
    "docvqa_val_lite": "Yaml",
    "textvqa_val_lite": "Yaml",
    "vizwiz_vqa_val_lite": "Yaml"
  },
  "n-shot": {
    "chartqa_lite": 0,
    "docvqa_val_lite": 0,
    "textvqa_val_lite": 0,
    "vizwiz_vqa_val_lite": 0
  },
  "higher_is_better": {
    "chartqa_lite": {
      "relaxed_overall": true,
      "relaxed_human_split": true,
      "relaxed_augmented_split": true
    },
    "docvqa_val_lite": {
      "anls": true
    },
    "textvqa_val_lite": {
      "exact_match": true,
      "submission": true
    },
    "vizwiz_vqa_val_lite": {
      "exact_match": true
    }
  },
  "n-samples": {
    "vizwiz_vqa_val_lite": {
      "original": 500,
      "effective": 100
    },
    "textvqa_val_lite": {
      "original": 500,
      "effective": 100
    },
    "docvqa_val_lite": {
      "original": 500,
      "effective": 100
    },
    "chartqa_lite": {
      "original": 500,
      "effective": 100
    }
  },
  "config": {
    "model": "upvla_mmu",
    "model_args": "model_config=policy_rollout/arvla_model_rollout_probe.yaml,device=cuda,dtype=fp32,max_new_tokens=32,temperature=1.0,top_k=1",
    "batch_size": "1",
    "batch_sizes": [],
    "device": null,
    "use_cache": null,
    "limit": 100.0,
    "offset": 0,
    "bootstrap_iters": 100000,
    "gen_kwargs": "",
    "random_seed": 0,
    "numpy_seed": 1234,
    "torch_seed": 1234,
    "fewshot_seed": 1234
  },
  "git_hash": "046ab1a",
  "date": "20260227_203343",
  "task_hashes": {},
  "model_source": "upvla_mmu",
  "model_name": "",
  "model_name_sanitized": "",
  "system_instruction": null,
  "system_instruction_sha": null,
  "fewshot_as_multiturn": false,
  "chat_template": null,
  "chat_template_sha": null,
  "start_time": 1596393.756182733,
  "end_time": 1597107.761028419,
  "total_evaluation_time_seconds": "714.004845686024"
}